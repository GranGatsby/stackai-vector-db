# StackAI Vector Database

Una API REST para indexar y consultar documentos en una base de datos vectorial, desarrollada como parte del proceso de entrevista tÃ©cnica de StackAI.

## ğŸš€ CaracterÃ­sticas

- **API REST completa** para operaciones CRUD en bibliotecas, documentos y chunks
- **BÃºsqueda vectorial k-NN** con mÃºltiples algoritmos de indexaciÃ³n
- **Arquitectura limpia** siguiendo principios DDD y SOLID
- **Logging estructurado** con request tracking y mÃºltiples formatters
- **Request middleware** con IDs Ãºnicos y mÃ©tricas de timing
- **Tipado estÃ¡tico** completo con MyPy
- **ContainerizaciÃ³n** con Docker
- **Herramientas de desarrollo** integradas (Black, Ruff, Pre-commit)
- **Suite de tests completa** con cobertura de componentes principales

## ğŸ“‹ Requisitos

- Python 3.12+
- Docker (opcional)
- Clave API de Cohere para embeddings

## ğŸ› ï¸ InstalaciÃ³n

### Desarrollo Local

1. **Clonar el repositorio**
   ```bash
   git clone <repository-url>
   cd stackai-vector-db
   ```

2. **Crear entorno virtual**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # o
   venv\Scripts\activate  # Windows
   ```

3. **Instalar dependencias de desarrollo**
   ```bash
   make setup
   # o manualmente:
   pip install -e ".[dev]"
   pre-commit install
   ```

4. **Configurar variables de entorno**
   ```bash
   cp env.example .env
   # Editar .env con tu clave API de Cohere
   ```

### Docker

```bash
# Construir imagen
make docker-build

# Ejecutar contenedor
make docker-run
```

## ğŸƒâ€â™‚ï¸ Uso

### Ejecutar la aplicaciÃ³n

```bash
# Desarrollo
make run

# O directamente
python -m app.main
```

La API estarÃ¡ disponible en `http://localhost:8000`

### DocumentaciÃ³n de la API

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

### Health Check

```bash
curl http://localhost:8000/api/v1/health
```

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
make test

# Ejecutar tests especÃ­ficos
pytest tests/test_health.py -v
pytest tests/test_config.py -v
pytest tests/test_logging.py -v

# Con cobertura
pytest tests/ --cov=app --cov-report=html

# Ejecutar solo tests unitarios
pytest tests/ -m "not integration" -v
```

### Tests Incluidos

- **test_health.py**: Tests para endpoints de health check y middleware
- **test_config.py**: Tests para configuraciÃ³n de Pydantic Settings
- **test_logging.py**: Tests para sistema de logging estructurado
- **test_main.py**: Tests para aplicaciÃ³n principal y middleware
- **test_schemas.py**: Tests para validaciÃ³n de esquemas Pydantic

## ğŸ”§ Herramientas de Desarrollo

```bash
# Formatear cÃ³digo
make format

# Linting
make lint

# Type checking
make type-check

# Ejecutar pre-commit hooks
make pre-commit

# Todas las verificaciones
make check
```

## ğŸ“ Estructura del Proyecto

```
stackai-vector-db/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/v1/routers/     # Endpoints de la API
â”‚   â”œâ”€â”€ core/               # ConfiguraciÃ³n y logging
â”‚   â”œâ”€â”€ domain/             # Entidades y lÃ³gica de negocio
â”‚   â”œâ”€â”€ services/           # Casos de uso de la aplicaciÃ³n
â”‚   â”œâ”€â”€ clients/            # Clientes externos (Cohere)
â”‚   â”œâ”€â”€ repositories/       # Interfaces y adaptadores de datos
â”‚   â”œâ”€â”€ indexes/            # Algoritmos de indexaciÃ³n vectorial
â”‚   â”œâ”€â”€ schemas/            # DTOs de Pydantic
â”‚   â”œâ”€â”€ utils/              # Utilidades
â”‚   â””â”€â”€ main.py             # Punto de entrada de la aplicaciÃ³n
â”œâ”€â”€ tests/                  # Tests unitarios e integraciÃ³n
â”œâ”€â”€ Dockerfile              # Imagen de Docker
â”œâ”€â”€ Makefile               # Comandos de desarrollo
â”œâ”€â”€ pyproject.toml         # ConfiguraciÃ³n del proyecto
â””â”€â”€ README.md              # Este archivo
```

## ğŸ—ï¸ Arquitectura

El proyecto sigue una arquitectura limpia basada en Domain-Driven Design (DDD):

- **API Layer**: Routers de FastAPI que manejan HTTP
- **Service Layer**: LÃ³gica de aplicaciÃ³n y casos de uso
- **Domain Layer**: Entidades y reglas de negocio
- **Repository Layer**: AbstracciÃ³n de persistencia
- **Infrastructure**: Implementaciones concretas (Ã­ndices, clientes)

## âš™ï¸ ConfiguraciÃ³n

Todas las configuraciones se manejan a travÃ©s de variables de entorno usando Pydantic Settings:

### Variables Principales

- `COHERE_API_KEY`: Clave API de Cohere (requerida)
- `DEFAULT_INDEX_TYPE`: Tipo de Ã­ndice por defecto (linear, kdtree, ivf)
- `MAX_CHUNKS_PER_LIBRARY`: MÃ¡ximo nÃºmero de chunks por biblioteca
- `LOG_LEVEL`: Nivel de logging (DEBUG, INFO, WARNING, ERROR)

### Logging ConfiguraciÃ³n

- `LOG_FORMAT_GENERAL`: Formato para logs generales
- `LOG_FORMAT_REQUEST`: Formato para logs de requests con campos estructurados
- Logging estructurado con request IDs Ãºnicos
- MÃºltiples handlers y formatters configurados via dictConfig

Ver `env.example` para todas las opciones disponibles.

## ğŸ” Algoritmos de IndexaciÃ³n

### Implementados

#### 1. LinearScanIndex (Baseline)
- **Complejidad Temporal**: 
  - Build: O(N) - Almacena vectores en memoria
  - Query: O(N Ã— D) - Escaneo exhaustivo
  - Add/Remove: O(1) - Operaciones directas en lista
- **Complejidad Espacial**: O(N Ã— D)
- **CaracterÃ­sticas**:
  - Resultados exactos (sin aproximaciÃ³n)
  - Sin preprocesamiento requerido
  - Excelente para datasets pequeÃ±os (<1K vectores)
  - Baseline confiable para comparaciÃ³n

#### 2. KDTreeIndex (Eficiente en Bajas Dimensiones)
- **Complejidad Temporal**:
  - Build: O(N log N) - Particionado recursivo con bÃºsqueda de mediana
  - Query: O(log N) promedio, O(N) peor caso
  - Add/Remove: O(log N) - Puede requerir rebalanceo
- **Complejidad Espacial**: O(N) - Estructura de Ã¡rbol
- **CaracterÃ­sticas**:
  - Excelente para dimensiones bajas (D â‰¤ 20)
  - Performance se degrada en altas dimensiones (maldiciÃ³n de dimensionalidad)
  - Resultados exactos
  - Estructura de memoria eficiente

#### 3. IVFIndex (Inverted File - Escalable)
- **Complejidad Temporal**:
  - Build: O(N Ã— C Ã— I) - N vectores, C clusters, I iteraciones k-means
  - Query: O(P Ã— M + k) - P sondeos, M vectores promedio por cluster
  - Add: O(C) - Encontrar cluster mÃ¡s cercano
  - Remove: O(M) - Buscar en lista invertida
- **Complejidad Espacial**: O(N + C Ã— D) - Vectores + centroides
- **CaracterÃ­sticas**:
  - Excelente escalabilidad para datasets grandes (>10K vectores)
  - Resultados aproximados (ajustable vÃ­a parÃ¡metro nprobe)
  - Buen rendimiento en altas dimensiones
  - Actualizaciones incrementales eficientes

### SelecciÃ³n AutomÃ¡tica de Algoritmo

El sistema selecciona automÃ¡ticamente el algoritmo Ã³ptimo basado en:

- **Datasets pequeÃ±os** (<1K vectores): LinearScan
- **Dimensiones bajas** (D â‰¤ 20, <50K vectores): KDTree  
- **Datasets grandes** (â‰¥10K vectores) o **altas dimensiones** (D > 50): IVF
- **Prioridad de precisiÃ³n**: KDTree para dim bajas, LinearScan para dim altas
- **Prioridad de velocidad**: IVF para la mayorÃ­a de casos

### JustificaciÃ³n de SelecciÃ³n

**Â¿Por quÃ© estos 3 algoritmos?**

1. **LinearScan**: Baseline esencial que garantiza resultados exactos y sirve como referencia de correctitud
2. **KDTree**: Algoritmo clÃ¡sico que demuestra tÃ©cnicas de particionado espacial, excelente para casos de uso especÃ­ficos
3. **IVF**: Algoritmo moderno usado en sistemas de producciÃ³n (similar a FAISS), escalable y prÃ¡ctico

Esta combinaciÃ³n cubre el espectro completo: exactitud vs velocidad, datasets pequeÃ±os vs grandes, y dimensiones bajas vs altas.

### Consideraciones de Concurrencia

- **Single-writer principle**: Operaciones de escritura protegidas con locks
- **Read/Write locks**: MÃºltiples lectores concurrentes permitidos
- **Thread-safe wrapper**: Envoltorio automÃ¡tico para operaciones concurrentes
- **Copy-on-write**: Lecturas desde snapshots inmutables durante reconstrucciÃ³n

## ğŸ› Troubleshooting

### Errores Comunes

1. **Clave API faltante**
   ```
   Error: COHERE_API_KEY is required
   ```
   SoluciÃ³n: Configurar la variable de entorno en `.env`

2. **Puerto en uso**
   ```
   Error: Address already in use
   ```
   SoluciÃ³n: Cambiar `PORT` en `.env` o terminar el proceso existente

## ğŸ“ TODO

### PrÃ³ximas Funcionalidades
- [ ] Crear servicios de aplicaciÃ³n para bÃºsqueda k-NN
- [ ] Implementar endpoints REST para bÃºsqueda vectorial
- [ ] Integrar indexaciÃ³n automÃ¡tica en LibraryService

### Mejoras Futuras (Extras)
- [ ] Implementar persistencia en disco
- [ ] Agregar filtros de metadata
- [ ] Implementar arquitectura leader-follower
- [ ] Crear SDK cliente de Python
- [ ] Agregar mÃ©tricas y monitoring

### âœ… Completado
- [x] Estructura base del proyecto con arquitectura DDD
- [x] ConfiguraciÃ³n de herramientas de desarrollo (Black, Ruff, MyPy)
- [x] Sistema de logging estructurado con mÃºltiples formatters
- [x] Request middleware con tracking de IDs Ãºnicos
- [x] Suite de tests completa para componentes base
- [x] ContainerizaciÃ³n con Docker
- [x] Health check endpoint funcional
- [x] **Modelos de dominio completos** (Library, Document, Chunk)
- [x] **Algoritmos de indexaciÃ³n implementados** (Linear, KD-Tree, IVF)
- [x] **Cliente Cohere para embeddings** con fallback a FakeClient
- [x] **Endpoints REST CRUD completos** para todas las entidades
- [x] **Sistema de embeddings integrado** con dependency injection
- [x] **Thread-safety y concurrencia** en algoritmos de indexaciÃ³n

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crear rama feature (`git checkout -b feature/amazing-feature`)
3. Commit cambios (`git commit -m 'Add amazing feature'`)
4. Push a la rama (`git push origin feature/amazing-feature`)
5. Abrir Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

---

**Desarrollado con â¤ï¸ para StackAI**
